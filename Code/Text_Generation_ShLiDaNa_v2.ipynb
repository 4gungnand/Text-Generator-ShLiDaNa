{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFWbEb6uGbN-"
      },
      "source": [
        "# ShLiDaNa TEXT GENERATOR v2\n",
        "\n",
        "Create a model that will predict the next word in a text sequence, implementing and training using a corpus of Different datasets, while also creating some helper functions to pre-process the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgXtktW6lWWg"
      },
      "source": [
        "OUR TEAM:\n",
        "\n",
        "| Name | NIM |\n",
        "|---|---|\n",
        "|Shahran Kurnia Ramadhan|21/476650/PA/20592|\n",
        "|Muhammad Linggar Ryanidha|21/475209/PA/20548|\n",
        "|Daniel Ardi Chandra|21/479046/PA/20780|\n",
        "|I Gusti Agung Premananda |21/473829/PA/20432|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BOwsuGQQY9OL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfd-nYKij5yY",
        "outputId": "2dc652b3-19db-4fc6-ccae-7cc9a87de0f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 5591 lines\n",
            "\n",
            "The first 5 lines look like this:\n",
            "\n",
            "@[cameras]\n",
            "@[glados says this if you place a portal on the wall under a camera.]\n",
            "to ensure the safe performance of all authorized activities, do not destroy \n",
            "vital testing apparatus.\n",
            "for your own safety, do not destroy vital testing apparatus.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Define path for file with datasets\n",
        "dataset_path = '..\\Datasets\\VGCoST_VideoGameDialogue_Corpus\\ENG\\Portal_merged.txt'\n",
        "\n",
        "# Read the data with the appropriate encoding\n",
        "with open(dataset_path, encoding='ISO-8859-1') as f:\n",
        "    data = f.read()\n",
        "\n",
        "# Remove unwanted characters using regex\n",
        "data = re.sub(r\"[\\\"']\", \"\", data)\n",
        "\n",
        "# Convert to lower case and save as a list\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "print(f\"There are {len(corpus)} lines\\n\")\n",
        "print(f\"The first 5 lines look like this:\\n\")\n",
        "for i in range(5):\n",
        "    print(corpus[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imB15zrSNhA1"
      },
      "source": [
        "## Tokenizing the text\n",
        "\n",
        "Now fit the Tokenizer to the corpus and save the total number of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AAhM_qAZk0o5"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tqhPxdeXlfjh",
        "outputId": "52fe94a3-c906-4fc8-ad6a-2ac3a3bac75e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'@[cameras]'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFMP4z11O3os"
      },
      "source": [
        "If you pass this text directly into the `texts_to_sequences` method you will get an unexpected result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qmgo-vXhk4nd",
        "outputId": "923c68da-e07d-4c09-e48c-13d483994edd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1012]]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences([corpus[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpTy8WmIQ57P",
        "outputId": "a3b63083-9210-497c-a945-d73678e5f21a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1012]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences([corpus[0]])[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oqy9KjXRJ9A"
      },
      "source": [
        "## Generating n_grams\n",
        "\n",
        "This function receives the fitted tokenizer and the corpus (which is a list of strings) and should return a list containing the `n_gram` sequences for each line in the corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iy4baJMDl6kj"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: n_gram_seqs\n",
        "def n_gram_seqs(corpus, tokenizer):\n",
        "\tinput_sequences = []\n",
        "\n",
        "\t### START CODE HERE\n",
        "\n",
        "\tfor line in corpus:\n",
        "\t\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "\t\tfor i in range(1, len(token_list)):\n",
        "\t\t\t# Generate subphrase\n",
        "\t\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\t\t# Append subphrase to input_sequences list\n",
        "\t\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\t### END CODE HERE\n",
        "\n",
        "\treturn input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlKqW2pfM7G3",
        "outputId": "d451a0a7-95e9-4749-837f-505b8107ba89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_gram sequences for first example look like this:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test your function with one example\n",
        "first_example_sequence = n_gram_seqs([corpus[0]], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for first example look like this:\\n\")\n",
        "first_example_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtPpCcBjNc4c",
        "outputId": "57abc3b5-3d23-4b13-9fcb-92c62b4bc944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_gram sequences for next 3 examples look like this:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[4, 377],\n",
              " [4, 377, 13],\n",
              " [4, 377, 13, 31],\n",
              " [4, 377, 13, 31, 2],\n",
              " [4, 377, 13, 31, 2, 187],\n",
              " [4, 377, 13, 31, 2, 187, 5],\n",
              " [4, 377, 13, 31, 2, 187, 5, 70],\n",
              " [4, 377, 13, 31, 2, 187, 5, 70, 17],\n",
              " [4, 377, 13, 31, 2, 187, 5, 70, 17, 1],\n",
              " [4, 377, 13, 31, 2, 187, 5, 70, 17, 1, 330],\n",
              " [4, 377, 13, 31, 2, 187, 5, 70, 17, 1, 330, 442],\n",
              " [4, 377, 13, 31, 2, 187, 5, 70, 17, 1, 330, 442, 5],\n",
              " [4, 377, 13, 31, 2, 187, 5, 70, 17, 1, 330, 442, 5, 1013],\n",
              " [3, 1014],\n",
              " [3, 1014, 1],\n",
              " [3, 1014, 1, 591],\n",
              " [3, 1014, 1, 591, 473],\n",
              " [3, 1014, 1, 591, 473, 6],\n",
              " [3, 1014, 1, 591, 473, 6, 34],\n",
              " [3, 1014, 1, 591, 473, 6, 34, 1886],\n",
              " [3, 1014, 1, 591, 473, 6, 34, 1886, 1485],\n",
              " [3, 1014, 1, 591, 473, 6, 34, 1886, 1485, 30],\n",
              " [3, 1014, 1, 591, 473, 6, 34, 1886, 1485, 30, 21],\n",
              " [3, 1014, 1, 591, 473, 6, 34, 1886, 1485, 30, 21, 555],\n",
              " [514, 71],\n",
              " [514, 71, 710]]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test your function with a bigger corpus\n",
        "next_3_examples_sequence = n_gram_seqs(corpus[1:4], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for next 3 examples look like this:\\n\")\n",
        "next_3_examples_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx3V_RjFWQSu"
      },
      "source": [
        "Apply the `n_gram_seqs` transformation to the whole corpus and save the maximum sequence length to use it later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laMwiRUpmuSd",
        "outputId": "e61f91fa-5faa-46e3-ed33-4ee637fb120a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_grams of input_sequences have length: 46418\n",
            "maximum length of sequences is: 21\n"
          ]
        }
      ],
      "source": [
        "# Apply the n_gram_seqs transformation to the whole corpus\n",
        "input_sequences = n_gram_seqs(corpus, tokenizer)\n",
        "\n",
        "# Save max length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "print(f\"n_grams of input_sequences have length: {len(input_sequences)}\")\n",
        "print(f\"maximum length of sequences is: {max_sequence_len}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHY7HroqWq12"
      },
      "source": [
        "## Add padding to the sequences\n",
        "\n",
        "Now code the `pad_seqs` function which will pad any given sequences to the desired maximum length. Notice that this function receives a list of sequences and should return a numpy array with the padded sequences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "code",
        "id": "WW1-qAZaWOhC"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: pad_seqs\n",
        "def pad_seqs(input_sequences, maxlen):\n",
        "    ### START CODE HERE\n",
        "    padded_sequences = pad_sequences(input_sequences, maxlen=maxlen, padding='pre')\n",
        "\n",
        "    return padded_sequences\n",
        "    ### END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqVQ0pb3YHLr",
        "outputId": "26560d7b-8ede-40b0-d819-14a726f64edf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([], shape=(0, 0), dtype=int32)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test your function with the n_grams_seq of the first example\n",
        "first_padded_seq = pad_seqs(first_example_sequence, len(first_example_sequence))\n",
        "first_padded_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j56_UCOBYzZt",
        "outputId": "1b46c8ea-b661-4aa6-8eb6-9b57cfd6b148"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    4,  377],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           4,  377,   13],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    4,\n",
              "         377,   13,   31],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    4,  377,\n",
              "          13,   31,    2],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    4,  377,   13,\n",
              "          31,    2,  187],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    4,  377,   13,   31,\n",
              "           2,  187,    5],\n",
              "       [   0,    0,    0,    0,    0,    0,    4,  377,   13,   31,    2,\n",
              "         187,    5,   70],\n",
              "       [   0,    0,    0,    0,    0,    4,  377,   13,   31,    2,  187,\n",
              "           5,   70,   17],\n",
              "       [   0,    0,    0,    0,    4,  377,   13,   31,    2,  187,    5,\n",
              "          70,   17,    1],\n",
              "       [   0,    0,    0,    4,  377,   13,   31,    2,  187,    5,   70,\n",
              "          17,    1,  330],\n",
              "       [   0,    0,    4,  377,   13,   31,    2,  187,    5,   70,   17,\n",
              "           1,  330,  442],\n",
              "       [   0,    4,  377,   13,   31,    2,  187,    5,   70,   17,    1,\n",
              "         330,  442,    5],\n",
              "       [   4,  377,   13,   31,    2,  187,    5,   70,   17,    1,  330,\n",
              "         442,    5, 1013],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    3, 1014],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           3, 1014,    1],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    3,\n",
              "        1014,    1,  591],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    3, 1014,\n",
              "           1,  591,  473],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    3, 1014,    1,\n",
              "         591,  473,    6],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    3, 1014,    1,  591,\n",
              "         473,    6,   34],\n",
              "       [   0,    0,    0,    0,    0,    0,    3, 1014,    1,  591,  473,\n",
              "           6,   34, 1886],\n",
              "       [   0,    0,    0,    0,    0,    3, 1014,    1,  591,  473,    6,\n",
              "          34, 1886, 1485],\n",
              "       [   0,    0,    0,    0,    3, 1014,    1,  591,  473,    6,   34,\n",
              "        1886, 1485,   30],\n",
              "       [   0,    0,    0,    3, 1014,    1,  591,  473,    6,   34, 1886,\n",
              "        1485,   30,   21],\n",
              "       [   0,    0,    3, 1014,    1,  591,  473,    6,   34, 1886, 1485,\n",
              "          30,   21,  555],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,  514,   71],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "         514,   71,  710]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test your function with the n_grams_seq of the next 3 examples\n",
        "next_3_padded_seq = pad_seqs(next_3_examples_sequence, max([len(s) for s in next_3_examples_sequence]))\n",
        "next_3_padded_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgK-Q_micEYA",
        "outputId": "4221880d-2049-4982-e77f-e6bc27049ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "padded corpus has shape: (46418, 21)\n"
          ]
        }
      ],
      "source": [
        "# Pad the whole corpus\n",
        "input_sequences = pad_seqs(input_sequences, max_sequence_len)\n",
        "\n",
        "print(f\"padded corpus has shape: {input_sequences.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbOidyPrXxf7"
      },
      "source": [
        "## Split the data into features and labels\n",
        "\n",
        "Before feeding the data into the neural network you should split it into features and labels. In this case the features will be the padded n_gram sequences with the last word removed from them and the labels will be the removed word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "code",
        "id": "9WGGbYdnZdmJ"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: features_and_labels\n",
        "def features_and_labels(input_sequences, total_words):\n",
        "    ### START CODE HERE\n",
        "    features = input_sequences[:,:-1]\n",
        "    labels = input_sequences[:,-1]\n",
        "    one_hot_labels = to_categorical(labels, num_classes=total_words)\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return features, one_hot_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23DolaBRaIAZ",
        "outputId": "092089a9-e01c-4cda-a488-918aa840f543"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "index -1 is out of bounds for axis 1 with size 0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\LENOVO\\Downloads\\programmer\\GitHub\\Text-Generator-ShLiDaNa\\Code\\Text_Generation_ShLiDaNa_linggar.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_linggar.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Test your function with the padded n_grams_seq of the first example\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_linggar.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m first_features, first_labels \u001b[39m=\u001b[39m features_and_labels(first_padded_seq, total_words)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_linggar.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlabels have shape: \u001b[39m\u001b[39m{\u001b[39;00mfirst_labels\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_linggar.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mfeatures look like this:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;32mc:\\Users\\LENOVO\\Downloads\\programmer\\GitHub\\Text-Generator-ShLiDaNa\\Code\\Text_Generation_ShLiDaNa_linggar.ipynb Cell 24\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_linggar.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeatures_and_labels\u001b[39m(input_sequences, total_words):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_linggar.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m### START CODE HERE\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_linggar.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     features \u001b[39m=\u001b[39m input_sequences[:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_linggar.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     labels \u001b[39m=\u001b[39m input_sequences[:,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_linggar.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     one_hot_labels \u001b[39m=\u001b[39m to_categorical(labels, num_classes\u001b[39m=\u001b[39mtotal_words)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_linggar.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m### END CODE HERE\u001b[39;00m\n",
            "\u001b[1;31mIndexError\u001b[0m: index -1 is out of bounds for axis 1 with size 0"
          ]
        }
      ],
      "source": [
        "# Test your function with the padded n_grams_seq of the first example\n",
        "first_features, first_labels = features_and_labels(first_padded_seq, total_words)\n",
        "\n",
        "print(f\"labels have shape: {first_labels.shape}\")\n",
        "print(\"\\nfeatures look like this:\\n\")\n",
        "first_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRTuLEt3bRKa",
        "outputId": "f7b8104b-cf81-4166-d502-7c4776bdac8d"
      },
      "outputs": [],
      "source": [
        "# Split the whole corpus\n",
        "features, labels = features_and_labels(input_sequences, total_words)\n",
        "\n",
        "print(f\"features have shape: {features.shape}\")\n",
        "print(f\"labels have shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltxaOCE_aU6J"
      },
      "source": [
        "## Create the model\n",
        "\n",
        "- Should implement Transformer encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "XrE6kpJFfvRY"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: create_model\n",
        "def create_model(total_words, max_sequence_len):\n",
        "\n",
        "    model = Sequential()\n",
        "    ### START CODE HERE\n",
        "    model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "    model.add(Bidirectional(LSTM(150)))\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IpX_Gu_gISk",
        "outputId": "d8612940-ba66-431e-e578-9dfaea5b08cb"
      },
      "outputs": [],
      "source": [
        "# Get the untrained model\n",
        "model = create_model(total_words, max_sequence_len)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(features, labels, epochs=50, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "1fXTEO3GJ282",
        "outputId": "1a711141-4505-4046-9356-01c1b568def3"
      },
      "outputs": [],
      "source": [
        "# Take a look at the training curves of your model\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjvED5A3qrn2"
      },
      "source": [
        "Download the `history.pkl` file which contains the information of the training history of your model and will be used to compute your grade. You can download this file by running the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9QRG73l6qE-c",
        "outputId": "8807fc83-84ec-4dc7-bc12-9893a6e55264"
      },
      "outputs": [],
      "source": [
        "def download_history():\n",
        "  import pickle\n",
        "  from google.colab import files\n",
        "\n",
        "  with open('history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "  files.download('history.pkl')\n",
        "\n",
        "download_history()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdsMszk9zBs_"
      },
      "source": [
        "## See our model in action\n",
        "\n",
        "After all our work it is finally time to see our model generating text.\n",
        "\n",
        "Run the cell below to generate the next 100 words of a seed text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vc6PHgxa6Hm",
        "outputId": "23e88f52-8c34-48f6-e1c0-cd33f70df20c"
      },
      "outputs": [],
      "source": [
        "seed_text = \"what is that\"\n",
        "next_words = 10\n",
        "\n",
        "for _ in range(next_words):\n",
        "\t# Convert the text into sequences\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\t# Pad the sequences\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t# Get the probabilities of predicting a word\n",
        "\tpredicted = model.predict(token_list, verbose=0)\n",
        "\t# Choose the next word based on the maximum probability\n",
        "\tpredicted = np.argmax(predicted, axis=-1).item()\n",
        "\t# Get the actual word from the word index\n",
        "\toutput_word = tokenizer.index_word[predicted]\n",
        "\t# Append to the current text\n",
        "\tseed_text += \" \" + output_word\n",
        "\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
