{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BOwsuGQQY9OL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFWbEb6uGbN-"
      },
      "source": [
        "# Game Dialogue Generator ver.999\n",
        "\n",
        "Creating a model that will magically predict the next words based on a text input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgXtktW6lWWg"
      },
      "source": [
        "OUR TEAM:\n",
        "\n",
        "| Name | NIM |\n",
        "|---|---|\n",
        "|Shahran Kurnia Ramadhan|21/476650/PA/20592|\n",
        "|Muhammad Linggar Ryanidha|21/475209/PA/20548|\n",
        "|Daniel Ardi Chandra|21/479046/PA/20780|\n",
        "|I Gusti Agung Premananda |21/473829/PA/20432|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 1000217976254383469\n",
            "xla_global_id: -1\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.13.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "Pfd-nYKij5yY",
        "outputId": "05c429bb-a2e4-461a-af15-f4bdc2af2ae5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 4916 lines\n",
            "\n",
            "The first 5 lines look like this:\n",
            "\n",
            "portal 2, valve, pc, ps3, xbox 360, 2011\n",
            "text extracted by oblivion from aoc, source: https://www.gamefaqs.com/pc/991073-portal-2/faqs/62236 (accessed 05/18/2017)\n",
            "\n",
            "announcer: explosion imminent. evacuate the facility immediately.\n",
            "announcer: warning. reactor core is at critical temperature.\n"
          ]
        }
      ],
      "source": [
        "# Define path for file with datasets\n",
        "dataset = '..\\Datasets\\VGCoST_VideoGameDialogue_Corpus\\ENG\\Portal 2 ENG.txt'\n",
        "\n",
        "# Define the datasets path\n",
        "# dataset = '..\\Datasets\\Efonte_DiscoElysium_Dialogue\\Efonte_DiscoElysium_dataset.txt'\n",
        "\n",
        "# Read the data\n",
        "with open(dataset, encoding='ISO-8859-1') as f:\n",
        "    data = f.read()\n",
        "\n",
        "# Remove unwanted characters using regex\n",
        "data = re.sub(r\"[@\\[\\\"'\\]]\", \"\", data)\n",
        "\n",
        "# Convert to lower case and save as a list\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "print(f\"There are {len(corpus)} lines\\n\")\n",
        "print(f\"The first 5 lines look like this:\\n\")\n",
        "for i in range(5):\n",
        "    print(corpus[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imB15zrSNhA1"
      },
      "source": [
        "## Tokenizing the text\n",
        "\n",
        "Now fit the Tokenizer to the corpus and save the total number of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # TESTING ONLY, COMMENT WHEN RUNNING FULL CODE\n",
        "# corpus = corpus[:200]\n",
        "# print(len(corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AAhM_qAZk0o5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total words: 5489\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(f\"Total words: {total_words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'to': 2,\n",
              " 'you': 3,\n",
              " 'glados': 4,\n",
              " 'a': 5,\n",
              " 'wheatley': 6,\n",
              " 'of': 7,\n",
              " 'i': 8,\n",
              " 'and': 9,\n",
              " 'that': 10,\n",
              " 'it': 11,\n",
              " 'in': 12,\n",
              " 'this': 13,\n",
              " 'we': 14,\n",
              " 'is': 15,\n",
              " 'for': 16,\n",
              " 'on': 17,\n",
              " 'turret': 18,\n",
              " 'me': 19,\n",
              " 'core': 20,\n",
              " 'just': 21,\n",
              " 'not': 22,\n",
              " 'was': 23,\n",
              " 'are': 24,\n",
              " 'have': 25,\n",
              " 'your': 26,\n",
              " 'be': 27,\n",
              " 'with': 28,\n",
              " 'if': 29,\n",
              " 'so': 30,\n",
              " 'do': 31,\n",
              " 'test': 32,\n",
              " 'defective': 33,\n",
              " 'but': 34,\n",
              " 'its': 35,\n",
              " 'up': 36,\n",
              " 'all': 37,\n",
              " 'im': 38,\n",
              " 'no': 39,\n",
              " 'dont': 40,\n",
              " 'one': 41,\n",
              " 'what': 42,\n",
              " 'there': 43,\n",
              " 'go': 44,\n",
              " 'space': 45,\n",
              " 'at': 46,\n",
              " 'out': 47,\n",
              " 'were': 48,\n",
              " 'know': 49,\n",
              " 'as': 50,\n",
              " 'oh': 51,\n",
              " 'going': 52,\n",
              " 'they': 53,\n",
              " 'youre': 54,\n",
              " 'get': 55,\n",
              " 'can': 56,\n",
              " 'here': 57,\n",
              " 'well': 58,\n",
              " 'now': 59,\n",
              " '1': 60,\n",
              " 'back': 61,\n",
              " 'would': 62,\n",
              " 'about': 63,\n",
              " 'like': 64,\n",
              " 'time': 65,\n",
              " 'my': 66,\n",
              " 'an': 67,\n",
              " 'portal': 68,\n",
              " 'way': 69,\n",
              " '3': 70,\n",
              " 'good': 71,\n",
              " 'them': 72,\n",
              " 'ill': 73,\n",
              " 'right': 74,\n",
              " 'look': 75,\n",
              " 'more': 76,\n",
              " 'announcer': 77,\n",
              " 'down': 78,\n",
              " 'from': 79,\n",
              " 'testing': 80,\n",
              " 'will': 81,\n",
              " 'some': 82,\n",
              " 'thats': 83,\n",
              " '2': 84,\n",
              " 'by': 85,\n",
              " 'when': 86,\n",
              " 'into': 87,\n",
              " 'had': 88,\n",
              " 'still': 89,\n",
              " 'us': 90,\n",
              " 'see': 91,\n",
              " 'make': 92,\n",
              " 'did': 93,\n",
              " 'cave': 94,\n",
              " 'johnson': 95,\n",
              " 'could': 96,\n",
              " 'how': 97,\n",
              " 'two': 98,\n",
              " 'got': 99,\n",
              " 'blue': 100,\n",
              " 'think': 101,\n",
              " 'players': 102,\n",
              " 'science': 103,\n",
              " 'or': 104,\n",
              " 'player': 105,\n",
              " 'come': 106,\n",
              " 'orange': 107,\n",
              " 'okay': 108,\n",
              " 'any': 109,\n",
              " 'cant': 110,\n",
              " 'these': 111,\n",
              " 'something': 112,\n",
              " 'through': 113,\n",
              " 'where': 114,\n",
              " 'again': 115,\n",
              " 'even': 116,\n",
              " 'because': 117,\n",
              " 'their': 118,\n",
              " 'alright': 119,\n",
              " 'other': 120,\n",
              " 'humans': 121,\n",
              " 'our': 122,\n",
              " 'very': 123,\n",
              " 'lets': 124,\n",
              " 'then': 125,\n",
              " 'tests': 126,\n",
              " 'been': 127,\n",
              " 'need': 128,\n",
              " 'than': 129,\n",
              " 'please': 130,\n",
              " 'really': 131,\n",
              " 'over': 132,\n",
              " 'only': 133,\n",
              " 'didnt': 134,\n",
              " 'too': 135,\n",
              " 'him': 136,\n",
              " 'yes': 137,\n",
              " 'before': 138,\n",
              " 'little': 139,\n",
              " 'while': 140,\n",
              " 'wait': 141,\n",
              " 'yeah': 142,\n",
              " 'want': 143,\n",
              " 'being': 144,\n",
              " 'should': 145,\n",
              " 'first': 146,\n",
              " 'off': 147,\n",
              " 'say': 148,\n",
              " 'take': 149,\n",
              " 'point': 150,\n",
              " 'doing': 151,\n",
              " 'let': 152,\n",
              " 'hey': 153,\n",
              " 'human': 154,\n",
              " 'aperture': 155,\n",
              " 'which': 156,\n",
              " 'keep': 157,\n",
              " 'ha': 158,\n",
              " 'he': 159,\n",
              " 'around': 160,\n",
              " 'next': 161,\n",
              " 'why': 162,\n",
              " 'tell': 163,\n",
              " 'has': 164,\n",
              " 'who': 165,\n",
              " 'much': 166,\n",
              " 'her': 167,\n",
              " 'made': 168,\n",
              " 'work': 169,\n",
              " 'ive': 170,\n",
              " 'button': 171,\n",
              " 'give': 172,\n",
              " 'things': 173,\n",
              " 'thought': 174,\n",
              " 'game': 175,\n",
              " 'put': 176,\n",
              " 'am': 177,\n",
              " 'also': 178,\n",
              " 'new': 179,\n",
              " 'feel': 180,\n",
              " 'gonna': 181,\n",
              " 'actually': 182,\n",
              " 'done': 183,\n",
              " 'theres': 184,\n",
              " 'might': 185,\n",
              " 'sorry': 186,\n",
              " 'stop': 187,\n",
              " 'room': 188,\n",
              " 'course': 189,\n",
              " 'most': 190,\n",
              " 'she': 191,\n",
              " 'youve': 192,\n",
              " 'those': 193,\n",
              " 'neurotoxin': 194,\n",
              " 'though': 195,\n",
              " 'hello': 196,\n",
              " 'lot': 197,\n",
              " 'idea': 198,\n",
              " 'never': 199,\n",
              " 'use': 200,\n",
              " 'his': 201,\n",
              " 'place': 202,\n",
              " 'hold': 203,\n",
              " 'old': 204,\n",
              " 'better': 205,\n",
              " 'door': 206,\n",
              " 'ah': 207,\n",
              " 'sure': 208,\n",
              " 'probably': 209,\n",
              " 'part': 210,\n",
              " 'thing': 211,\n",
              " 'try': 212,\n",
              " 'wanted': 213,\n",
              " 'fine': 214,\n",
              " 'long': 215,\n",
              " 'best': 216,\n",
              " 'anything': 217,\n",
              " 'big': 218,\n",
              " 'hes': 219,\n",
              " 'find': 220,\n",
              " 'press': 221,\n",
              " 'help': 222,\n",
              " 'last': 223,\n",
              " 'dun': 224,\n",
              " 'once': 225,\n",
              " 'important': 226,\n",
              " 'great': 227,\n",
              " 'bit': 228,\n",
              " 'after': 229,\n",
              " 'dead': 230,\n",
              " 'break': 231,\n",
              " 'solve': 232,\n",
              " 'yourself': 233,\n",
              " 'guess': 234,\n",
              " 'both': 235,\n",
              " 'another': 236,\n",
              " 'paint': 237,\n",
              " 'nothing': 238,\n",
              " 'whats': 239,\n",
              " 'kill': 240,\n",
              " 'times': 241,\n",
              " 'isnt': 242,\n",
              " 'love': 243,\n",
              " 'fact': 244,\n",
              " 'world': 245,\n",
              " 'pretty': 246,\n",
              " 'ever': 247,\n",
              " 'sphere': 248,\n",
              " 'everything': 249,\n",
              " 'enough': 250,\n",
              " 'fun': 251,\n",
              " 'five': 252,\n",
              " 'start': 253,\n",
              " 'may': 254,\n",
              " 'subjects': 255,\n",
              " 'getting': 256,\n",
              " 'gel': 257,\n",
              " 'life': 258,\n",
              " 'die': 259,\n",
              " 'people': 260,\n",
              " 'pick': 261,\n",
              " 'used': 262,\n",
              " 'lady': 263,\n",
              " 'center': 264,\n",
              " 'remember': 265,\n",
              " 'almost': 266,\n",
              " 'turrets': 267,\n",
              " 'since': 268,\n",
              " 'wanna': 269,\n",
              " 'plan': 270,\n",
              " 'bird': 271,\n",
              " 'puzzle': 272,\n",
              " 'caroline': 273,\n",
              " 'chambers': 274,\n",
              " 'hear': 275,\n",
              " 'run': 276,\n",
              " 'maybe': 277,\n",
              " 'points': 278,\n",
              " 'each': 279,\n",
              " 'heh': 280,\n",
              " 'death': 281,\n",
              " 'body': 282,\n",
              " 'portals': 283,\n",
              " 'brain': 284,\n",
              " 'doesnt': 285,\n",
              " 'found': 286,\n",
              " 'trying': 287,\n",
              " 'facility': 288,\n",
              " 'three': 289,\n",
              " 'control': 290,\n",
              " 'open': 291,\n",
              " 'said': 292,\n",
              " 'does': 293,\n",
              " 'few': 294,\n",
              " 'eye': 295,\n",
              " 'gun': 296,\n",
              " 'side': 297,\n",
              " 'different': 298,\n",
              " 'deadly': 299,\n",
              " 'wrong': 300,\n",
              " 'id': 301,\n",
              " 'surprise': 302,\n",
              " 'needed': 303,\n",
              " 'such': 304,\n",
              " 'moment': 305,\n",
              " 'turn': 306,\n",
              " 'ba': 307,\n",
              " 'end': 308,\n",
              " 'looking': 309,\n",
              " 'far': 310,\n",
              " 'making': 311,\n",
              " 'told': 312,\n",
              " 'wont': 313,\n",
              " 'voice': 314,\n",
              " 'always': 315,\n",
              " 'show': 316,\n",
              " 'honest': 317,\n",
              " 'together': 318,\n",
              " 'same': 319,\n",
              " 'chamber': 320,\n",
              " 'machine': 321,\n",
              " 'problem': 322,\n",
              " 'close': 323,\n",
              " 'jump': 324,\n",
              " 'courses': 325,\n",
              " 'congratulations': 326,\n",
              " 'must': 327,\n",
              " 'wall': 328,\n",
              " 'either': 329,\n",
              " 'anyway': 330,\n",
              " 'youll': 331,\n",
              " 'ahead': 332,\n",
              " 'whole': 333,\n",
              " 'robot': 334,\n",
              " 'using': 335,\n",
              " 'else': 336,\n",
              " 'plug': 337,\n",
              " 'minutes': 338,\n",
              " 'fire': 339,\n",
              " 'enrichment': 340,\n",
              " 'objects': 341,\n",
              " 'theyre': 342,\n",
              " 'years': 343,\n",
              " 'thinking': 344,\n",
              " 'real': 345,\n",
              " 'interesting': 346,\n",
              " 'onto': 347,\n",
              " 'behind': 348,\n",
              " 'pull': 349,\n",
              " 'collaboration': 350,\n",
              " 'came': 351,\n",
              " 'youd': 352,\n",
              " 'without': 353,\n",
              " 'co': 354,\n",
              " 'welcome': 355,\n",
              " 'simple': 356,\n",
              " 'stay': 357,\n",
              " 'working': 358,\n",
              " 'bad': 359,\n",
              " 'gotta': 360,\n",
              " 'saying': 361,\n",
              " 'moving': 362,\n",
              " 'solution': 363,\n",
              " 'ow': 364,\n",
              " 'lift': 365,\n",
              " 'ready': 366,\n",
              " 'floor': 367,\n",
              " 'head': 368,\n",
              " 'earth': 369,\n",
              " 'line': 370,\n",
              " 'god': 371,\n",
              " 'laugh': 372,\n",
              " 'day': 373,\n",
              " 'care': 374,\n",
              " 'man': 375,\n",
              " 'hit': 376,\n",
              " 'own': 377,\n",
              " 'every': 378,\n",
              " 'case': 379,\n",
              " 'heres': 380,\n",
              " 'comes': 381,\n",
              " 'job': 382,\n",
              " 'alive': 383,\n",
              " 'hard': 384,\n",
              " 'ping': 385,\n",
              " 'escape': 386,\n",
              " 'playtesters': 387,\n",
              " 'op': 388,\n",
              " 'level': 389,\n",
              " 'computer': 390,\n",
              " 'subject': 391,\n",
              " 'stand': 392,\n",
              " 'thanks': 393,\n",
              " 'worry': 394,\n",
              " 'power': 395,\n",
              " 'box': 396,\n",
              " 'until': 397,\n",
              " 'many': 398,\n",
              " 'ended': 399,\n",
              " 'designed': 400,\n",
              " 'arent': 401,\n",
              " 'team': 402,\n",
              " 'robots': 403,\n",
              " 'tried': 404,\n",
              " 'high': 405,\n",
              " 'uh': 406,\n",
              " 'moron': 407,\n",
              " 'bloody': 408,\n",
              " 'clickclickclick': 409,\n",
              " 'stalemate': 410,\n",
              " 'continue': 411,\n",
              " 'tool': 412,\n",
              " 'levels': 413,\n",
              " 'em': 414,\n",
              " 'hundred': 415,\n",
              " 'hand': 416,\n",
              " 'word': 417,\n",
              " 'yet': 418,\n",
              " 'gave': 419,\n",
              " 'reassembly': 420,\n",
              " 'play': 421,\n",
              " 'ohhh': 422,\n",
              " 'created': 423,\n",
              " 'device': 424,\n",
              " 'second': 425,\n",
              " 'become': 426,\n",
              " 'happened': 427,\n",
              " 'finally': 428,\n",
              " 'trust': 429,\n",
              " 'i\\x92m': 430,\n",
              " 'potato': 431,\n",
              " 'brilliant': 432,\n",
              " 'originally': 433,\n",
              " 'wasnt': 434,\n",
              " 'light': 435,\n",
              " 'went': 436,\n",
              " 'puzzles': 437,\n",
              " 'design': 438,\n",
              " 'percent': 439,\n",
              " 'within': 440,\n",
              " 'results': 441,\n",
              " 'running': 442,\n",
              " 'simply': 443,\n",
              " 'emancipation': 444,\n",
              " 'complete': 445,\n",
              " 'less': 446,\n",
              " 'fast': 447,\n",
              " 'between': 448,\n",
              " 'news': 449,\n",
              " 'earlier': 450,\n",
              " 'difficult': 451,\n",
              " 'glass': 452,\n",
              " 'listen': 453,\n",
              " 'favorite': 454,\n",
              " 'hi': 455,\n",
              " 'killing': 456,\n",
              " 'having': 457,\n",
              " 'perfect': 458,\n",
              " 'partner': 459,\n",
              " 'outside': 460,\n",
              " 'talking': 461,\n",
              " 'least': 462,\n",
              " 'seriously': 463,\n",
              " 'bullets': 464,\n",
              " 'sound': 465,\n",
              " 'watch': 466,\n",
              " 'small': 467,\n",
              " 'horrible': 468,\n",
              " 'solved': 469,\n",
              " 'lair': 470,\n",
              " 'whoa': 471,\n",
              " 'self': 472,\n",
              " 'hub': 473,\n",
              " 'call': 474,\n",
              " 'buzzer': 475,\n",
              " 'cube': 476,\n",
              " 'someone': 477,\n",
              " 'exit': 478,\n",
              " 'built': 479,\n",
              " 'entirely': 480,\n",
              " 'spheres': 481,\n",
              " 'water': 482,\n",
              " 'makes': 483,\n",
              " 'walk': 484,\n",
              " 'killed': 485,\n",
              " 'fail': 486,\n",
              " 'person': 487,\n",
              " 'fall': 488,\n",
              " 'easy': 489,\n",
              " 'ten': 490,\n",
              " 'shut': 491,\n",
              " 'excellent': 492,\n",
              " 'understand': 493,\n",
              " 'quite': 494,\n",
              " 'model': 495,\n",
              " 'often': 496,\n",
              " 'broken': 497,\n",
              " 'original': 498,\n",
              " 'obviously': 499,\n",
              " 'decided': 500,\n",
              " 'um': 501,\n",
              " 'click': 502,\n",
              " 'animation': 503,\n",
              " 'map': 504,\n",
              " 'completing': 505,\n",
              " 'experience': 506,\n",
              " 'non': 507,\n",
              " 'however': 508,\n",
              " 'dangerous': 509,\n",
              " 'require': 510,\n",
              " 'avoid': 511,\n",
              " 'performance': 512,\n",
              " 'cough': 513,\n",
              " 'seven': 514,\n",
              " 'shes': 515,\n",
              " 'stuff': 516,\n",
              " 'couldnt': 517,\n",
              " 'already': 518,\n",
              " 'hope': 519,\n",
              " 'happen': 520,\n",
              " 'havent': 521,\n",
              " 'werent': 522,\n",
              " 'under': 523,\n",
              " 'happy': 524,\n",
              " 'hang': 525,\n",
              " 'touch': 526,\n",
              " 'invented': 527,\n",
              " 'elevator': 528,\n",
              " 'twelve': 529,\n",
              " 'trouble': 530,\n",
              " 'anyone': 531,\n",
              " 'quick': 532,\n",
              " 'looks': 533,\n",
              " 'mind': 534,\n",
              " 'ya': 535,\n",
              " 'create': 536,\n",
              " 'leave': 537,\n",
              " 'lesson': 538,\n",
              " 'luck': 539,\n",
              " 'added': 540,\n",
              " 'kind': 541,\n",
              " 'build': 542,\n",
              " 'story': 543,\n",
              " 'worked': 544,\n",
              " 'move': 545,\n",
              " 'slow': 546,\n",
              " 'knew': 547,\n",
              " 'early': 548,\n",
              " 'simulation': 549,\n",
              " 'system': 550,\n",
              " 'four': 551,\n",
              " 'emergency': 552,\n",
              " 'due': 553,\n",
              " 'future': 554,\n",
              " 'attempt': 555,\n",
              " 'live': 556,\n",
              " 'taught': 557,\n",
              " 'longer': 558,\n",
              " 'left': 559,\n",
              " 'house': 560,\n",
              " 'wouldnt': 561,\n",
              " 'sounds': 562,\n",
              " 'ride': 563,\n",
              " 'started': 564,\n",
              " 'weve': 565,\n",
              " 'took': 566,\n",
              " 'along': 567,\n",
              " 'believe': 568,\n",
              " 'change': 569,\n",
              " 'building': 570,\n",
              " 'dying': 571,\n",
              " 'weight': 572,\n",
              " 'act': 573,\n",
              " 'name': 574,\n",
              " 'guy': 575,\n",
              " 'completely': 576,\n",
              " 'funny': 577,\n",
              " 'others': 578,\n",
              " 'agree': 579,\n",
              " 'number': 580,\n",
              " 'rather': 581,\n",
              " 'trap': 582,\n",
              " 'absolutely': 583,\n",
              " 'gestures': 584,\n",
              " 'sort': 585,\n",
              " 'says': 586,\n",
              " 'stupid': 587,\n",
              " 'crap': 588,\n",
              " 'instead': 589,\n",
              " 'character': 590,\n",
              " 'warning': 591,\n",
              " 'required': 592,\n",
              " 'answer': 593,\n",
              " 'associate': 594,\n",
              " 'available': 595,\n",
              " 'safety': 596,\n",
              " 'thank': 597,\n",
              " 'nine': 598,\n",
              " 'recorded': 599,\n",
              " 'environment': 600,\n",
              " 'playing': 601,\n",
              " 'during': 602,\n",
              " 'areas': 603,\n",
              " 'personality': 604,\n",
              " 'lemons': 605,\n",
              " 'supposed': 606,\n",
              " 'whos': 607,\n",
              " 'holding': 608,\n",
              " 'goodbye': 609,\n",
              " 'lab': 610,\n",
              " 'myself': 611,\n",
              " 'lovely': 612,\n",
              " 'standing': 613,\n",
              " 'repulsion': 614,\n",
              " 'chance': 615,\n",
              " 'six': 616,\n",
              " 'worst': 617,\n",
              " 'experiment': 618,\n",
              " 'ohhhh': 619,\n",
              " 'pens': 620,\n",
              " 'error': 621,\n",
              " 'nice': 622,\n",
              " 'somewhere': 623,\n",
              " 'nobody': 624,\n",
              " 'exactly': 625,\n",
              " 'catch': 626,\n",
              " 'anymore': 627,\n",
              " 'penalized': 628,\n",
              " 'fault': 629,\n",
              " 'blah': 630,\n",
              " 'hurt': 631,\n",
              " 'save': 632,\n",
              " 'win': 633,\n",
              " 'problems': 634,\n",
              " 'seems': 635,\n",
              " 'lights': 636,\n",
              " 'failure': 637,\n",
              " 'watching': 638,\n",
              " 'themselves': 639,\n",
              " 'starting': 640,\n",
              " 'away': 641,\n",
              " 'surface': 642,\n",
              " 'forever': 643,\n",
              " 'learn': 644,\n",
              " 'ideas': 645,\n",
              " 'saw': 646,\n",
              " 'lying': 647,\n",
              " 'damage': 648,\n",
              " 'doors': 649,\n",
              " 'careful': 650,\n",
              " 'allow': 651,\n",
              " 'stuck': 652,\n",
              " 'games': 653,\n",
              " 'clever': 654,\n",
              " 'masher': 655,\n",
              " 'looked': 656,\n",
              " 'rail': 657,\n",
              " 'meant': 658,\n",
              " 'explosion': 659,\n",
              " 'reactor': 660,\n",
              " 'fifty': 661,\n",
              " 'days': 662,\n",
              " 'vault': 663,\n",
              " 'lie': 664,\n",
              " 'pressure': 665,\n",
              " 'reaction': 666,\n",
              " 'material': 667,\n",
              " 'inside': 668,\n",
              " 'face': 669,\n",
              " 'smooth': 670,\n",
              " 'result': 671,\n",
              " 'bring': 672,\n",
              " 'pain': 673,\n",
              " 'coming': 674,\n",
              " 'telling': 675,\n",
              " 'involves': 676,\n",
              " 'follow': 677,\n",
              " 'whatever': 678,\n",
              " 'full': 679,\n",
              " 'size': 680,\n",
              " 'free': 681,\n",
              " 'opportunity': 682,\n",
              " 'paying': 683,\n",
              " 'cool': 684,\n",
              " 'home': 685,\n",
              " 'soon': 686,\n",
              " 'allowed': 687,\n",
              " 'able': 688,\n",
              " 'writing': 689,\n",
              " 'accidentally': 690,\n",
              " 'air': 691,\n",
              " 'everyone': 692,\n",
              " 'entire': 693,\n",
              " 'anywhere': 694,\n",
              " 'fat': 695,\n",
              " 'laughter': 696,\n",
              " 'teamwork': 697,\n",
              " 'purpose': 698,\n",
              " 'mean': 699,\n",
              " 'cooperative': 700,\n",
              " 'list': 701,\n",
              " 'it\\x92s': 702,\n",
              " 'eventually': 703,\n",
              " 'hate': 704,\n",
              " 'faith': 705,\n",
              " 'plate': 706,\n",
              " 'deep': 707,\n",
              " 'expected': 708,\n",
              " 'ways': 709,\n",
              " 'correct': 710,\n",
              " 'final': 711,\n",
              " 'itself': 712,\n",
              " 'idiot': 713,\n",
              " 'seen': 714,\n",
              " 'agh': 715,\n",
              " 'pit': 716,\n",
              " 'parents': 717,\n",
              " 'giving': 718,\n",
              " 'shoot': 719,\n",
              " 'gesture': 720,\n",
              " 'felt': 721,\n",
              " 'solving': 722,\n",
              " 'pop': 723,\n",
              " 'progress': 724,\n",
              " 'characters': 725,\n",
              " 'fizzler': 726,\n",
              " 'tag': 727,\n",
              " 'resolution': 728,\n",
              " 'cannot': 729,\n",
              " 'intelligence': 730,\n",
              " 'training': 731,\n",
              " 'completed': 732,\n",
              " 'state': 733,\n",
              " 'physical': 734,\n",
              " 'ceiling': 735,\n",
              " 'event': 736,\n",
              " 'based': 737,\n",
              " 'happening': 738,\n",
              " 'starts': 739,\n",
              " 'write': 740,\n",
              " 'grill': 741,\n",
              " 'lethal': 742,\n",
              " 'listening': 743,\n",
              " 'active': 744,\n",
              " 'template': 745,\n",
              " 'debris': 746,\n",
              " 'equipment': 747,\n",
              " 'physics': 748,\n",
              " 'trapped': 749,\n",
              " 'moon': 750,\n",
              " 'gives': 751,\n",
              " 'ago': 752,\n",
              " 'hell': 753,\n",
              " 'boys': 754,\n",
              " 'meet': 755,\n",
              " 'waiting': 756,\n",
              " 'group': 757,\n",
              " 'mentioned': 758,\n",
              " 'talk': 759,\n",
              " 'adventure': 760,\n",
              " 'sixty': 761,\n",
              " 'twenty': 762,\n",
              " 'noticed': 763,\n",
              " 'serious': 764,\n",
              " 'miss': 765,\n",
              " 'turned': 766,\n",
              " 'somebody': 767,\n",
              " 'asking': 768,\n",
              " 'friend': 769,\n",
              " 'called': 770,\n",
              " 'apart': 771,\n",
              " 'holes': 772,\n",
              " 'sun': 773,\n",
              " 'friends': 774,\n",
              " 'past': 775,\n",
              " 'paradox': 776,\n",
              " 'himself': 777,\n",
              " 'ability': 778,\n",
              " 'eyes': 779,\n",
              " 'woman': 780,\n",
              " 'arm': 781,\n",
              " 'set': 782,\n",
              " 'given': 783,\n",
              " 'busy': 784,\n",
              " 'failing': 785,\n",
              " 'perfectly': 786,\n",
              " 'fair': 787,\n",
              " 'clear': 788,\n",
              " 'cores': 789,\n",
              " 'extremely': 790,\n",
              " 'easier': 791,\n",
              " 'cubes': 792,\n",
              " 'pass': 793,\n",
              " 'smell': 794,\n",
              " 'changed': 795,\n",
              " 'add': 796,\n",
              " 'sometimes': 797,\n",
              " 'impossible': 798,\n",
              " 'laughs': 799,\n",
              " 'wow': 800,\n",
              " 'sense': 801,\n",
              " 'nevermind': 802,\n",
              " 'crazy': 803,\n",
              " 'seeing': 804,\n",
              " 'order': 805,\n",
              " 'natural': 806,\n",
              " 'gibberish': 807,\n",
              " 'motion': 808,\n",
              " 'bet': 809,\n",
              " 'minute': 810,\n",
              " 'figure': 811,\n",
              " 'mate': 812,\n",
              " 'huge': 813,\n",
              " 'speed': 814,\n",
              " 'silence': 815,\n",
              " 'path': 816,\n",
              " 'approach': 817,\n",
              " 'sequence': 818,\n",
              " 'began': 819,\n",
              " 'bot': 820,\n",
              " 'mechanics': 821,\n",
              " 'became': 822,\n",
              " 'corruption': 823,\n",
              " 'prepare': 824,\n",
              " 'code': 825,\n",
              " 'research': 826,\n",
              " 'currently': 827,\n",
              " 'front': 828,\n",
              " 'technical': 829,\n",
              " 'pre': 830,\n",
              " 'begin': 831,\n",
              " 'tubes': 832,\n",
              " 'jazz': 833,\n",
              " 'lines': 834,\n",
              " 'towards': 835,\n",
              " 'shot': 836,\n",
              " 'missing': 837,\n",
              " 'lack': 838,\n",
              " 'interaction': 839,\n",
              " 'rest': 840,\n",
              " 'note': 841,\n",
              " 'form': 842,\n",
              " 'quality': 843,\n",
              " 'literally': 844,\n",
              " 'jumping': 845,\n",
              " 'everybody': 846,\n",
              " 'shell': 847,\n",
              " 'mad': 848,\n",
              " 'special': 849,\n",
              " 'fear': 850,\n",
              " 'sir': 851,\n",
              " 'track': 852,\n",
              " 'rules': 853,\n",
              " 'poor': 854,\n",
              " 'thousand': 855,\n",
              " 'tiny': 856,\n",
              " 'likely': 857,\n",
              " 'realize': 858,\n",
              " 'black': 859,\n",
              " 'ones': 860,\n",
              " 'oo': 861,\n",
              " 'boy': 862,\n",
              " 'bam': 863,\n",
              " 'star': 864,\n",
              " 'cat': 865,\n",
              " 'hot': 866,\n",
              " 'half': 867,\n",
              " '4': 868,\n",
              " 'later': 869,\n",
              " 'died': 870,\n",
              " 'kept': 871,\n",
              " 'thorn': 872,\n",
              " 'notice': 873,\n",
              " 'dunna': 874,\n",
              " 'knows': 875,\n",
              " 'screen': 876,\n",
              " 'happens': 877,\n",
              " 'ridiculous': 878,\n",
              " 'b': 879,\n",
              " 'partners': 880,\n",
              " 'indicate': 881,\n",
              " 'sake': 882,\n",
              " 'alarm': 883,\n",
              " 'wed': 884,\n",
              " 'reassemble': 885,\n",
              " 'faster': 886,\n",
              " 'receives': 887,\n",
              " 'valuable': 888,\n",
              " 'tested': 889,\n",
              " 'chell': 890,\n",
              " 'massive': 891,\n",
              " 'hours': 892,\n",
              " 'afraid': 893,\n",
              " 'honestly': 894,\n",
              " 'grab': 895,\n",
              " 'showing': 896,\n",
              " 'effect': 897,\n",
              " 'seconds': 898,\n",
              " 'attention': 899,\n",
              " 'cruel': 900,\n",
              " 'opening': 901,\n",
              " 'smelly': 902,\n",
              " 'asked': 903,\n",
              " 'grid': 904,\n",
              " 'switch': 905,\n",
              " 'matter': 906,\n",
              " 'scared': 907,\n",
              " 'charge': 908,\n",
              " 'option': 909,\n",
              " 'clap': 910,\n",
              " 'area': 911,\n",
              " 'falling': 912,\n",
              " 'arms': 913,\n",
              " 'cards': 914,\n",
              " 'escaping': 915,\n",
              " 'bombs': 916,\n",
              " 'actual': 917,\n",
              " 'short': 918,\n",
              " 'monitors': 919,\n",
              " 'smash': 920,\n",
              " 'stick': 921,\n",
              " 'hack': 922,\n",
              " 'pod': 923,\n",
              " 'apple': 924,\n",
              " 'realized': 925,\n",
              " 'grip': 926,\n",
              " 'dang': 927,\n",
              " 'gameplay': 928,\n",
              " 'commentary': 929,\n",
              " 'wheatleys': 930,\n",
              " 'funnel': 931,\n",
              " 'destruction': 932,\n",
              " 'container': 933,\n",
              " 'simulations': 934,\n",
              " 'materials': 935,\n",
              " 'linear': 936,\n",
              " 'balance': 937,\n",
              " 'seemed': 938,\n",
              " 'bots': 939,\n",
              " 'bounce': 940,\n",
              " 'immediately': 941,\n",
              " 'manual': 942,\n",
              " 'substitute': 943,\n",
              " 'detected': 944,\n",
              " 'central': 945,\n",
              " 'initiate': 946,\n",
              " 'transfer': 947,\n",
              " 'procedure': 948,\n",
              " 'unless': 949,\n",
              " 'return': 950,\n",
              " 'security': 951,\n",
              " 're': 952,\n",
              " 'federal': 953,\n",
              " 'relaxation': 954,\n",
              " 'art': 955,\n",
              " 'music': 956,\n",
              " 'potentially': 957,\n",
              " 'protocols': 958,\n",
              " 'remains': 959,\n",
              " 'twice': 960,\n",
              " 'relax': 961,\n",
              " 'apply': 962,\n",
              " 'remain': 963,\n",
              " 'certain': 964,\n",
              " 'reason': 965,\n",
              " 'redemption': 966,\n",
              " 'process': 967,\n",
              " 'memory': 968,\n",
              " 'although': 969,\n",
              " 'low': 970,\n",
              " 'questions': 971,\n",
              " 'read': 972,\n",
              " 'laws': 973,\n",
              " 'message': 974,\n",
              " 'movement': 975,\n",
              " 'heard': 976,\n",
              " 'conversion': 977,\n",
              " 'dollars': 978,\n",
              " 'million': 979,\n",
              " 'ground': 980,\n",
              " 'tape': 981,\n",
              " 'allright': 982,\n",
              " 'burn': 983,\n",
              " 'means': 984,\n",
              " 'taking': 985,\n",
              " 'against': 986,\n",
              " 'release': 987,\n",
              " 'top': 988,\n",
              " 'element': 989,\n",
              " 'today': 990,\n",
              " 'lead': 991,\n",
              " 'heart': 992,\n",
              " 'itll': 993,\n",
              " 'type': 994,\n",
              " 'types': 995,\n",
              " 'question': 996,\n",
              " 'proud': 997,\n",
              " 'closer': 998,\n",
              " 'hmm': 999,\n",
              " 'bored': 1000,\n",
              " ...}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oqy9KjXRJ9A"
      },
      "source": [
        "## Generating n_grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iy4baJMDl6kj"
      },
      "outputs": [],
      "source": [
        "def n_gram_seqs(corpus, tokenizer):\n",
        "\tinput_sequences = []\n",
        "\tfor line in corpus:\n",
        "\t\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\t\tfor i in range(1, len(token_list)):\n",
        "\t\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\t\tinput_sequences.append(n_gram_sequence)\n",
        "\treturn input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['text extracted by oblivion from aoc, source: https://www.gamefaqs.com/pc/991073-portal-2/faqs/62236 (accessed 05/18/2017)',\n",
              " '',\n",
              " 'announcer: explosion imminent. evacuate the facility immediately.']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus[1:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtPpCcBjNc4c",
        "outputId": "a16238cd-17d9-4b99-c639-82145890475f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_gram sequences for next 3 examples look like this:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[2611, 2612],\n",
              " [2611, 2612, 85],\n",
              " [2611, 2612, 85, 2613],\n",
              " [2611, 2612, 85, 2613, 79],\n",
              " [2611, 2612, 85, 2613, 79, 2614],\n",
              " [2611, 2612, 85, 2613, 79, 2614, 1124],\n",
              " [2611, 2612, 85, 2613, 79, 2614, 1124, 2615],\n",
              " [2611, 2612, 85, 2613, 79, 2614, 1124, 2615, 2616],\n",
              " [2611, 2612, 85, 2613, 79, 2614, 1124, 2615, 2616, 2617],\n",
              " [2611, 2612, 85, 2613, 79, 2614, 1124, 2615, 2616, 2617, 1774],\n",
              " [2611, 2612, 85, 2613, 79, 2614, 1124, 2615, 2616, 2617, 1774, 1771],\n",
              " [2611, 2612, 85, 2613, 79, 2614, 1124, 2615, 2616, 2617, 1774, 1771, 2618],\n",
              " [2611,\n",
              "  2612,\n",
              "  85,\n",
              "  2613,\n",
              "  79,\n",
              "  2614,\n",
              "  1124,\n",
              "  2615,\n",
              "  2616,\n",
              "  2617,\n",
              "  1774,\n",
              "  1771,\n",
              "  2618,\n",
              "  68],\n",
              " [2611,\n",
              "  2612,\n",
              "  85,\n",
              "  2613,\n",
              "  79,\n",
              "  2614,\n",
              "  1124,\n",
              "  2615,\n",
              "  2616,\n",
              "  2617,\n",
              "  1774,\n",
              "  1771,\n",
              "  2618,\n",
              "  68,\n",
              "  84],\n",
              " [2611,\n",
              "  2612,\n",
              "  85,\n",
              "  2613,\n",
              "  79,\n",
              "  2614,\n",
              "  1124,\n",
              "  2615,\n",
              "  2616,\n",
              "  2617,\n",
              "  1774,\n",
              "  1771,\n",
              "  2618,\n",
              "  68,\n",
              "  84,\n",
              "  2619],\n",
              " [2611,\n",
              "  2612,\n",
              "  85,\n",
              "  2613,\n",
              "  79,\n",
              "  2614,\n",
              "  1124,\n",
              "  2615,\n",
              "  2616,\n",
              "  2617,\n",
              "  1774,\n",
              "  1771,\n",
              "  2618,\n",
              "  68,\n",
              "  84,\n",
              "  2619,\n",
              "  2620],\n",
              " [2611,\n",
              "  2612,\n",
              "  85,\n",
              "  2613,\n",
              "  79,\n",
              "  2614,\n",
              "  1124,\n",
              "  2615,\n",
              "  2616,\n",
              "  2617,\n",
              "  1774,\n",
              "  1771,\n",
              "  2618,\n",
              "  68,\n",
              "  84,\n",
              "  2619,\n",
              "  2620,\n",
              "  2621],\n",
              " [2611,\n",
              "  2612,\n",
              "  85,\n",
              "  2613,\n",
              "  79,\n",
              "  2614,\n",
              "  1124,\n",
              "  2615,\n",
              "  2616,\n",
              "  2617,\n",
              "  1774,\n",
              "  1771,\n",
              "  2618,\n",
              "  68,\n",
              "  84,\n",
              "  2619,\n",
              "  2620,\n",
              "  2621,\n",
              "  2622],\n",
              " [2611,\n",
              "  2612,\n",
              "  85,\n",
              "  2613,\n",
              "  79,\n",
              "  2614,\n",
              "  1124,\n",
              "  2615,\n",
              "  2616,\n",
              "  2617,\n",
              "  1774,\n",
              "  1771,\n",
              "  2618,\n",
              "  68,\n",
              "  84,\n",
              "  2619,\n",
              "  2620,\n",
              "  2621,\n",
              "  2622,\n",
              "  1775],\n",
              " [2611,\n",
              "  2612,\n",
              "  85,\n",
              "  2613,\n",
              "  79,\n",
              "  2614,\n",
              "  1124,\n",
              "  2615,\n",
              "  2616,\n",
              "  2617,\n",
              "  1774,\n",
              "  1771,\n",
              "  2618,\n",
              "  68,\n",
              "  84,\n",
              "  2619,\n",
              "  2620,\n",
              "  2621,\n",
              "  2622,\n",
              "  1775,\n",
              "  2623],\n",
              " [77, 659],\n",
              " [77, 659, 1776],\n",
              " [77, 659, 1776, 2624],\n",
              " [77, 659, 1776, 2624, 1],\n",
              " [77, 659, 1776, 2624, 1, 288],\n",
              " [77, 659, 1776, 2624, 1, 288, 941]]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test function\n",
        "test_3_seq = n_gram_seqs(corpus[1:4], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for next 3 examples look like this:\\n\")\n",
        "test_3_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx3V_RjFWQSu"
      },
      "source": [
        "Apply the `n_gram_seqs` transformation to the whole corpus and save the maximum sequence length to use it later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laMwiRUpmuSd",
        "outputId": "a78d5ad9-c4e0-41dd-e291-01df3fb7d0ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_grams of input_sequences have length: 42579\n",
            "maximum length of sequences is: 21\n"
          ]
        }
      ],
      "source": [
        "# Apply the n_gram_seqs transformation to the whole corpus\n",
        "input_sequences = n_gram_seqs(corpus, tokenizer)\n",
        "\n",
        "# Save max length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "print(f\"n_grams of input_sequences have length: {len(input_sequences)}\")\n",
        "print(f\"maximum length of sequences is: {max_sequence_len}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHY7HroqWq12"
      },
      "source": [
        "## Add padding to the sequences\n",
        "\n",
        "We padd the sequences so they have the same length and efficient when being feeded into the machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgK-Q_micEYA",
        "outputId": "e203e4a9-9fd7-4ee3-f242-f471cf84f584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "padded corpus has shape: (42579, 21)\n"
          ]
        }
      ],
      "source": [
        "# Pad the whole corpus\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "\n",
        "print(f\"padded corpus has shape: {input_sequences.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbOidyPrXxf7"
      },
      "source": [
        "## Split the data into features and labels\n",
        "\n",
        "Before feeding the data into the neural network you should split it into features and labels. In this case the features will be the padded n_gram sequences with the last word removed from them and the labels will be the removed word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "code",
        "id": "9WGGbYdnZdmJ"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: features_and_labels\n",
        "def features_and_labels(input_sequences, total_words):\n",
        "    features = input_sequences[:,:-1]\n",
        "    labels = input_sequences[:,-1]\n",
        "    one_hot_labels = to_categorical(labels, num_classes=total_words)\n",
        "    return features, one_hot_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRTuLEt3bRKa",
        "outputId": "87c3a158-1bf6-4316-c8d0-05dee2a0a776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features have shape: (42579, 20)\n",
            "labels have shape: (42579, 5489)\n"
          ]
        }
      ],
      "source": [
        "# Split the whole corpus\n",
        "features, labels = features_and_labels(input_sequences, total_words)\n",
        "\n",
        "print(f\"features have shape: {features.shape}\")\n",
        "print(f\"labels have shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# RATIO for TRAIN / VAL / TEST: 60/20/20\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "train_features, val_features, train_labels, val_labels = train_test_split(train_features, train_labels, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25547, 25547, 8516, 8516, 8516, 8516)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_features), len(train_labels), len(val_features), len(val_labels), len(test_features), len(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltxaOCE_aU6J"
      },
      "source": [
        "# LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the parameters\n",
        "VOCAB_SIZE = total_words  \n",
        "EMBEDDING_DIM = 256\n",
        "EPOCH = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "cellView": "code",
        "id": "XrE6kpJFfvRY"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "def create_model_lstm(rnn_units, dropout):\n",
        "    model = Sequential([\n",
        "        Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=max_sequence_len-1),\n",
        "        Bidirectional(LSTM(rnn_units, dropout=dropout)), # This is the core GRU layer\n",
        "        Dense(VOCAB_SIZE, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the hyperparameters\n",
        "dropout = [0.2, 0.3, 0.4]\n",
        "rnn_units = [128, 256, 512]\n",
        "# dropout = [0.2]\n",
        "# rnn_units = [128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IpX_Gu_gISk",
        "outputId": "a45bdd81-0056-4dd1-fb24-16a33b87d8f7"
      },
      "outputs": [],
      "source": [
        "# Fix the Compatibility issue\n",
        "tf.compat.v1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter tuning for LSTM without keras wrapper\n",
        "def hyperparameter_tuning_lstm(train_features, train_labels, val_features, val_labels):\n",
        "    # Define the results dictionary\n",
        "    results = {}\n",
        "\n",
        "    # Loop over all possible combinations of hyperparameters\n",
        "    for ru in rnn_units:\n",
        "        for do in dropout:\n",
        "            # Create the model using the current hyperparameters\n",
        "            model = create_model_lstm(ru, do)\n",
        "            model.fit(train_features, train_labels, epochs=5, verbose=2, validation_data=(val_features, val_labels))\n",
        "\n",
        "            # Get the latest validation accuracy\n",
        "            acc = model.history.history['val_accuracy'][-1]\n",
        "\n",
        "            # Save the results\n",
        "            results[(ru, do)] = acc\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 25547 samples, validate on 8516 samples\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\LENOVO\\Downloads\\programmer\\GitHub\\Text-Generator-ShLiDaNa\\Code\\Text_Generation_ShLiDaNa_v999 - seperated.ipynb Cell 31\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999%20-%20seperated.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Hyperparameter tuning for LSTM\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999%20-%20seperated.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result \u001b[39m=\u001b[39m hyperparameter_tuning_lstm(train_features, train_labels, val_features, val_labels)\n",
            "\u001b[1;32mc:\\Users\\LENOVO\\Downloads\\programmer\\GitHub\\Text-Generator-ShLiDaNa\\Code\\Text_Generation_ShLiDaNa_v999 - seperated.ipynb Cell 31\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999%20-%20seperated.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m do \u001b[39min\u001b[39;00m dropout:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999%20-%20seperated.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# Create the model using the current hyperparameters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999%20-%20seperated.ipynb#X42sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     model \u001b[39m=\u001b[39m create_model_lstm(ru, do)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999%20-%20seperated.ipynb#X42sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(train_features, train_labels, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(val_features, val_labels))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999%20-%20seperated.ipynb#X42sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Get the latest validation accuracy\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999%20-%20seperated.ipynb#X42sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:856\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_call_args(\u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    855\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 856\u001b[0m \u001b[39mreturn\u001b[39;00m func\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    857\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    858\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    859\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    860\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    861\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m    862\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    863\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    864\u001b[0m     validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[0;32m    865\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m    866\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m    867\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m    868\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    869\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m    870\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m    871\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m    872\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m    873\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m    874\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m    875\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m    876\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training_arrays_v1.py:734\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    729\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`validation_steps` should not be specified if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    730\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`validation_data` is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    731\u001b[0m         )\n\u001b[0;32m    732\u001b[0m     val_x, val_y, val_sample_weights \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m \u001b[39mreturn\u001b[39;00m fit_loop(\n\u001b[0;32m    735\u001b[0m     model,\n\u001b[0;32m    736\u001b[0m     inputs\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    737\u001b[0m     targets\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    738\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weights,\n\u001b[0;32m    739\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    740\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m    741\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    742\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    743\u001b[0m     val_inputs\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m    744\u001b[0m     val_targets\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m    745\u001b[0m     val_sample_weights\u001b[39m=\u001b[39;49mval_sample_weights,\n\u001b[0;32m    746\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m    747\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m    748\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m    749\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m    750\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m    751\u001b[0m     steps_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msteps_per_epoch\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    752\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training_arrays_v1.py:421\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m callbacks\u001b[39m.\u001b[39m_call_batch_hook(\n\u001b[0;32m    417\u001b[0m     mode, \u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m, batch_index, batch_logs\n\u001b[0;32m    418\u001b[0m )\n\u001b[0;32m    420\u001b[0m \u001b[39m# Get outputs.\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m batch_outs \u001b[39m=\u001b[39m f(ins_batch)\n\u001b[0;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(batch_outs, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    423\u001b[0m     batch_outs \u001b[39m=\u001b[39m [batch_outs]\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:4609\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4599\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   4600\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callable_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   4601\u001b[0m     \u001b[39mor\u001b[39;00m feed_arrays \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feed_arrays\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4605\u001b[0m     \u001b[39mor\u001b[39;00m session \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\n\u001b[0;32m   4606\u001b[0m ):\n\u001b[0;32m   4607\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[1;32m-> 4609\u001b[0m fetched \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_callable_fn(\u001b[39m*\u001b[39;49marray_vals, run_metadata\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_metadata)\n\u001b[0;32m   4610\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetches) :])\n\u001b[0;32m   4611\u001b[0m output_structure \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4612\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs_structure,\n\u001b[0;32m   4613\u001b[0m     fetched[: \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs)],\n\u001b[0;32m   4614\u001b[0m     expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   4615\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1482\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1481\u001b[0m   run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1482\u001b[0m   ret \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39;49mTF_SessionRunCallable(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49m_session,\n\u001b[0;32m   1483\u001b[0m                                          \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle, args,\n\u001b[0;32m   1484\u001b[0m                                          run_metadata_ptr)\n\u001b[0;32m   1485\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m   1486\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Hyperparameter tuning for LSTM\n",
        "result = hyperparameter_tuning_lstm(train_features, train_labels, val_features, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: (128, 0.2) \t Val Accuracy: 0.052941177040338516\n",
            "Hyperparameters: (128, 0.3) \t Val Accuracy: 0.04117647185921669\n",
            "Hyperparameters: (128, 0.4) \t Val Accuracy: 0.03529411926865578\n",
            "Hyperparameters: (256, 0.2) \t Val Accuracy: 0.0470588244497776\n",
            "Hyperparameters: (256, 0.3) \t Val Accuracy: 0.01764705963432789\n",
            "Hyperparameters: (256, 0.4) \t Val Accuracy: 0.029411764815449715\n",
            "Hyperparameters: (512, 0.2) \t Val Accuracy: 0.05882352963089943\n",
            "Hyperparameters: (512, 0.3) \t Val Accuracy: 0.052941177040338516\n",
            "Hyperparameters: (512, 0.4) \t Val Accuracy: 0.04117647185921669\n",
            "Best hyperparameters: (512, 0.2)\n"
          ]
        }
      ],
      "source": [
        "# Print the results LSTM hyperparameter tuning\n",
        "for key, value in result.items():\n",
        "    print(f\"Hyperparameters: {key} \\t Val Accuracy: {value}\")\n",
        "print(f\"Best hyperparameters: {max(result, key=result.get)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the best hyperparameters\n",
        "rnn_units_best = max(result, key=result.get)[0]\n",
        "dropout_best = max(result, key=result.get)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 510 samples, validate on 170 samples\n",
            "Epoch 1/100\n",
            "510/510 [==============================] - 5s 11ms/sample - loss: 5.8464 - accuracy: 0.0353 - val_loss: 6.0121 - val_accuracy: 0.0235\n",
            "Epoch 2/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 5.3089 - accuracy: 0.0353 - val_loss: 6.1229 - val_accuracy: 0.0529\n",
            "Epoch 3/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 5.1482 - accuracy: 0.0588 - val_loss: 6.4767 - val_accuracy: 0.0118\n",
            "Epoch 4/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 5.0786 - accuracy: 0.0706 - val_loss: 6.8338 - val_accuracy: 0.0529\n",
            "Epoch 5/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 4.9825 - accuracy: 0.0765 - val_loss: 6.7506 - val_accuracy: 0.0353\n",
            "Epoch 6/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 4.8697 - accuracy: 0.0784 - val_loss: 7.1055 - val_accuracy: 0.0529\n",
            "Epoch 7/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 4.6947 - accuracy: 0.0902 - val_loss: 7.2014 - val_accuracy: 0.0471\n",
            "Epoch 8/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 4.4832 - accuracy: 0.0941 - val_loss: 7.1268 - val_accuracy: 0.0588\n",
            "Epoch 9/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 4.2504 - accuracy: 0.1137 - val_loss: 7.2894 - val_accuracy: 0.0412\n",
            "Epoch 10/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 3.9161 - accuracy: 0.1569 - val_loss: 7.2621 - val_accuracy: 0.0706\n",
            "Epoch 11/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 3.6100 - accuracy: 0.1765 - val_loss: 7.6425 - val_accuracy: 0.0824\n",
            "Epoch 12/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 3.3117 - accuracy: 0.2235 - val_loss: 8.0993 - val_accuracy: 0.0765\n",
            "Epoch 13/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 2.9214 - accuracy: 0.2804 - val_loss: 8.4277 - val_accuracy: 0.1059\n",
            "Epoch 14/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 2.5915 - accuracy: 0.3039 - val_loss: 8.0669 - val_accuracy: 0.0824\n",
            "Epoch 15/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 2.3197 - accuracy: 0.3941 - val_loss: 8.7948 - val_accuracy: 0.0882\n",
            "Epoch 16/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 1.9587 - accuracy: 0.4490 - val_loss: 8.7126 - val_accuracy: 0.0941\n",
            "Epoch 17/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 1.6864 - accuracy: 0.5294 - val_loss: 9.6762 - val_accuracy: 0.0941\n",
            "Epoch 18/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 1.5322 - accuracy: 0.5686 - val_loss: 9.8350 - val_accuracy: 0.1000\n",
            "Epoch 19/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 1.2802 - accuracy: 0.6490 - val_loss: 9.8674 - val_accuracy: 0.0941\n",
            "Epoch 20/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 1.1026 - accuracy: 0.7078 - val_loss: 9.8385 - val_accuracy: 0.1059\n",
            "Epoch 21/100\n",
            "510/510 [==============================] - 4s 7ms/sample - loss: 0.9150 - accuracy: 0.7686 - val_loss: 10.2878 - val_accuracy: 0.1176\n",
            "Epoch 22/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.7804 - accuracy: 0.8078 - val_loss: 10.2061 - val_accuracy: 0.0941\n",
            "Epoch 23/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 0.6574 - accuracy: 0.8294 - val_loss: 10.4345 - val_accuracy: 0.1000\n",
            "Epoch 24/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.6059 - accuracy: 0.8392 - val_loss: 10.3533 - val_accuracy: 0.1059\n",
            "Epoch 25/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.4993 - accuracy: 0.8980 - val_loss: 10.7656 - val_accuracy: 0.0941\n",
            "Epoch 26/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.4407 - accuracy: 0.8980 - val_loss: 10.9639 - val_accuracy: 0.1118\n",
            "Epoch 27/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.3646 - accuracy: 0.9098 - val_loss: 10.9687 - val_accuracy: 0.1059\n",
            "Epoch 28/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.3042 - accuracy: 0.9353 - val_loss: 11.1116 - val_accuracy: 0.1059\n",
            "Epoch 29/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.2726 - accuracy: 0.9275 - val_loss: 11.4135 - val_accuracy: 0.0882\n",
            "Epoch 30/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.2469 - accuracy: 0.9569 - val_loss: 11.2939 - val_accuracy: 0.0941\n",
            "Epoch 31/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.2182 - accuracy: 0.9490 - val_loss: 11.1080 - val_accuracy: 0.0882\n",
            "Epoch 32/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 0.2010 - accuracy: 0.9549 - val_loss: 11.3482 - val_accuracy: 0.1000\n",
            "Epoch 33/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.1797 - accuracy: 0.9510 - val_loss: 11.4199 - val_accuracy: 0.0941\n",
            "Epoch 34/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.1695 - accuracy: 0.9608 - val_loss: 11.3966 - val_accuracy: 0.0824\n",
            "Epoch 35/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.1747 - accuracy: 0.9549 - val_loss: 11.4513 - val_accuracy: 0.0882\n",
            "Epoch 36/100\n",
            "510/510 [==============================] - 4s 7ms/sample - loss: 0.1556 - accuracy: 0.9627 - val_loss: 11.7257 - val_accuracy: 0.1000\n",
            "Epoch 37/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.1515 - accuracy: 0.9510 - val_loss: 11.6734 - val_accuracy: 0.1000\n",
            "Epoch 38/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.1365 - accuracy: 0.9549 - val_loss: 11.8578 - val_accuracy: 0.1000\n",
            "Epoch 39/100\n",
            "510/510 [==============================] - 4s 7ms/sample - loss: 0.1204 - accuracy: 0.9588 - val_loss: 11.7290 - val_accuracy: 0.0941\n",
            "Epoch 40/100\n",
            "510/510 [==============================] - 3s 7ms/sample - loss: 0.1204 - accuracy: 0.9588 - val_loss: 11.8843 - val_accuracy: 0.1059\n",
            "Epoch 41/100\n",
            "510/510 [==============================] - 4s 7ms/sample - loss: 0.1205 - accuracy: 0.9647 - val_loss: 11.7592 - val_accuracy: 0.0941\n",
            "Epoch 42/100\n",
            "510/510 [==============================] - 4s 7ms/sample - loss: 0.1290 - accuracy: 0.9569 - val_loss: 11.8715 - val_accuracy: 0.1059\n",
            "Epoch 43/100\n",
            "510/510 [==============================] - 4s 7ms/sample - loss: 0.1215 - accuracy: 0.9549 - val_loss: 11.9077 - val_accuracy: 0.1059\n",
            "Epoch 44/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.1256 - accuracy: 0.9627 - val_loss: 11.7377 - val_accuracy: 0.1118\n",
            "Epoch 45/100\n",
            "510/510 [==============================] - 4s 7ms/sample - loss: 0.1060 - accuracy: 0.9569 - val_loss: 12.0503 - val_accuracy: 0.1000\n",
            "Epoch 46/100\n",
            "510/510 [==============================] - 4s 7ms/sample - loss: 0.1060 - accuracy: 0.9608 - val_loss: 11.5623 - val_accuracy: 0.1000\n",
            "Epoch 47/100\n",
            "510/510 [==============================] - 4s 7ms/sample - loss: 0.1074 - accuracy: 0.9627 - val_loss: 11.9163 - val_accuracy: 0.1000\n",
            "Epoch 48/100\n",
            "510/510 [==============================] - 4s 7ms/sample - loss: 0.1108 - accuracy: 0.9647 - val_loss: 11.9682 - val_accuracy: 0.1000\n",
            "Epoch 49/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.0986 - accuracy: 0.9647 - val_loss: 11.8192 - val_accuracy: 0.0941\n",
            "Epoch 50/100\n",
            "510/510 [==============================] - 3s 6ms/sample - loss: 0.1020 - accuracy: 0.9588 - val_loss: 12.0914 - val_accuracy: 0.0941\n",
            "Epoch 51/100\n",
            "320/510 [=================>............] - ETA: 1s - loss: 0.1025 - accuracy: 0.9500"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\LENOVO\\Downloads\\programmer\\GitHub\\Text-Generator-ShLiDaNa\\Code\\Text_Generation_ShLiDaNa_v999.ipynb Cell 34\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Use the best hyperparameters to create the final model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_lstm \u001b[39m=\u001b[39m create_model_lstm(rnn_units_best, dropout_best)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m history \u001b[39m=\u001b[39m model_lstm\u001b[39m.\u001b[39;49mfit(train_features, train_labels, epochs\u001b[39m=\u001b[39;49mEPOCH, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(val_features, val_labels))\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:856\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_call_args(\u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    855\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 856\u001b[0m \u001b[39mreturn\u001b[39;00m func\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    857\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    858\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    859\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    860\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    861\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m    862\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    863\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    864\u001b[0m     validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[0;32m    865\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m    866\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m    867\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m    868\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    869\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m    870\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m    871\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m    872\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m    873\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m    874\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m    875\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m    876\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training_arrays_v1.py:734\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    729\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`validation_steps` should not be specified if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    730\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`validation_data` is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    731\u001b[0m         )\n\u001b[0;32m    732\u001b[0m     val_x, val_y, val_sample_weights \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m \u001b[39mreturn\u001b[39;00m fit_loop(\n\u001b[0;32m    735\u001b[0m     model,\n\u001b[0;32m    736\u001b[0m     inputs\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    737\u001b[0m     targets\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    738\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weights,\n\u001b[0;32m    739\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    740\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m    741\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    742\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    743\u001b[0m     val_inputs\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m    744\u001b[0m     val_targets\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m    745\u001b[0m     val_sample_weights\u001b[39m=\u001b[39;49mval_sample_weights,\n\u001b[0;32m    746\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m    747\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m    748\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m    749\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m    750\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m    751\u001b[0m     steps_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msteps_per_epoch\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    752\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training_arrays_v1.py:421\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m callbacks\u001b[39m.\u001b[39m_call_batch_hook(\n\u001b[0;32m    417\u001b[0m     mode, \u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m, batch_index, batch_logs\n\u001b[0;32m    418\u001b[0m )\n\u001b[0;32m    420\u001b[0m \u001b[39m# Get outputs.\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m batch_outs \u001b[39m=\u001b[39m f(ins_batch)\n\u001b[0;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(batch_outs, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    423\u001b[0m     batch_outs \u001b[39m=\u001b[39m [batch_outs]\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:4609\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4599\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   4600\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callable_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   4601\u001b[0m     \u001b[39mor\u001b[39;00m feed_arrays \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feed_arrays\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4605\u001b[0m     \u001b[39mor\u001b[39;00m session \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\n\u001b[0;32m   4606\u001b[0m ):\n\u001b[0;32m   4607\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[1;32m-> 4609\u001b[0m fetched \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_callable_fn(\u001b[39m*\u001b[39;49marray_vals, run_metadata\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_metadata)\n\u001b[0;32m   4610\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetches) :])\n\u001b[0;32m   4611\u001b[0m output_structure \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4612\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs_structure,\n\u001b[0;32m   4613\u001b[0m     fetched[: \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs)],\n\u001b[0;32m   4614\u001b[0m     expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   4615\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1482\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1481\u001b[0m   run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1482\u001b[0m   ret \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39;49mTF_SessionRunCallable(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49m_session,\n\u001b[0;32m   1483\u001b[0m                                          \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle, args,\n\u001b[0;32m   1484\u001b[0m                                          run_metadata_ptr)\n\u001b[0;32m   1485\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m   1486\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Use the best hyperparameters to create the final model\n",
        "model_lstm = create_model_lstm(rnn_units_best, dropout_best)\n",
        "\n",
        "history = model_lstm.fit(train_features, train_labels, epochs=EPOCH, verbose=1, validation_data=(val_features, val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "1fXTEO3GJ282",
        "outputId": "17d8ff54-00d7-4d9b-e13d-a3dcde7c0649"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the training and validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 5.95495863685831 \t Accuracy: 0.017543859779834747\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "loss, acc = model_lstm.evaluate(test_features, test_labels, verbose=1)\n",
        "print(f\"Loss: {loss} \\t Accuracy: {acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GRU Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define model with gru layer\n",
        "def create_model_gru(rnn_units, dropout):\n",
        "\n",
        "    model = Sequential([\n",
        "        Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=max_sequence_len-1),\n",
        "        Bidirectional(GRU(rnn_units, dropout=dropout)),\n",
        "        Dense(VOCAB_SIZE, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 510 samples, validate on 170 samples\n",
            "510/510 [==============================] - 21s 41ms/sample - loss: 6.0118 - accuracy: 0.0412 - val_loss: 5.9462 - val_accuracy: 0.0529\n",
            "Loss: 5.901117915995637 \t Accuracy: 0.05263157933950424\n"
          ]
        }
      ],
      "source": [
        "model_gru = create_model_gru(rnn_units_best, dropout_best)\n",
        "\n",
        "history_gru = model_gru.fit(train_features, train_labels, epochs=EPOCH, verbose=1, validation_data=(val_features, val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the training and validation accuracy\n",
        "plt.plot(history_gru.history['accuracy'])\n",
        "plt.plot(history_gru.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "loss_gru, acc_gru = model_gru.evaluate(test_features, test_labels, verbose=1)\n",
        "print(f\"Loss: {loss_gru} \\t Accuracy: {acc_gru}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjvED5A3qrn2"
      },
      "source": [
        "# Downloading the model and tokenizer\n",
        "- `model.h5`: used to predict the output word in the deployment stage.\n",
        "- `tokenizer.pkl`: used to tokenize the words in the deployment stage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Save the model\n",
        "# model_lstm.save('model.h5')\n",
        "\n",
        "# # Save the tokenizer\n",
        "# with open('tokenizer.pkl', 'wb') as handle:\n",
        "#     pkl.dump(tokenizer, handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdsMszk9zBs_"
      },
      "source": [
        "## Test the model\n",
        "Run the cell below and let the model generate the next 20 words of a seed text. You can change the seed text to whatever you want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LSTM predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vc6PHgxa6Hm",
        "outputId": "7c4fe60f-e76a-4f37-dd3b-e15492973d6c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\LENOVO\\Downloads\\programmer\\GitHub\\Text-Generator-ShLiDaNa\\Code\\Text_Generation_ShLiDaNa_v999.ipynb Cell 46\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999.ipynb#X62sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m seed_text_gru \u001b[39m=\u001b[39m seed_text\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999.ipynb#X62sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Convert the text into sequences\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999.ipynb#X62sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m token_list \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mtexts_to_sequences([seed_text])[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999.ipynb#X62sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Pad the sequences\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Downloads/programmer/GitHub/Text-Generator-ShLiDaNa/Code/Text_Generation_ShLiDaNa_v999.ipynb#X62sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m token_list \u001b[39m=\u001b[39m pad_sequences([token_list], maxlen\u001b[39m=\u001b[39mmax_sequence_len\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpre\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "seed_text = \"please do not\"\n",
        "next_words = 20\n",
        "\n",
        "for _ in range(next_words):\n",
        "\tseed_text_gru = seed_text\n",
        "\t# Convert the text into sequences\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "\t# Pad the sequences\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t\n",
        "\t# Get the probabilities of predicting a word\n",
        "\tpredicted = model_lstm.predict(token_list, verbose=0)\n",
        "\tpredicted_gru = model_gru.predict(token_list, verbose=0)\n",
        "\t\n",
        "\t# Choose the next word based on the maximum probability\n",
        "\tpredicted = np.argmax(predicted, axis=-1).item()\n",
        "\tpredicted_gru = np.argmax(predicted_gru, axis=-1).item()\n",
        "\t\n",
        "\t# Get the actual word from the word index\n",
        "\toutput_word = tokenizer.index_word[predicted]\n",
        "\toutput_word_gru = tokenizer.index_word[predicted_gru]\n",
        "\t\n",
        "\t# Append to the current text\n",
        "\tseed_text += \" \" + output_word\n",
        "\tseed_text_gru += \" \" + output_word_gru\n",
        "\n",
        "print(f\"This is the predicted text using LSTM: \\n{seed_text}\")\n",
        "print(f\"This is the predicted text using GRU: \\n{seed_text_gru}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
